diff --git a/infer_one.py b/infer_one.py
index fa52998..1fddba6 100644
--- a/infer_one.py
+++ b/infer_one.py
@@ -36,7 +36,7 @@ def main(_):
 
     D_POSE_VEC = 51
 
-    D_MODEL = 300
+    D_MODEL = 240
     N_LAYERS = 2
     N_HEAD = 8
     D_K, D_V = 64, 64
@@ -46,8 +46,7 @@ def main(_):
     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
 
     encoder = Encoder(max_seq_len=142,
-                      input_size=INPUT_SIZE,
-                      d_word_vec=D_MODEL,
+                      music_size=INPUT_SIZE,
                       n_layers=N_LAYERS,
                       n_head=N_HEAD,
                       d_k=D_K,
@@ -56,10 +55,9 @@ def main(_):
                       d_inner=D_INNER,
                       dropout=DROPOUT)
 
-    decoder = Decoder(input_size=D_POSE_VEC,
-                      d_word_vec=D_POSE_VEC,
+    decoder = Decoder(motion_size=D_POSE_VEC,
+                      d_emb=D_POSE_VEC,
                       hidden_size=D_INNER,
-                      encoder_d_model=D_MODEL,
                       dropout=DROPOUT)
 
 
@@ -68,7 +66,7 @@ def main(_):
                   lambda_v=0.01,
                   device=device)
 
-    pretrained_dict = torch.load(model_parameters, map_location='cpu')['model']
+    pretrained_dict = torch.load(model_parameters, map_location='cpu')
     # pretrained_dict = torch.load(model_parameters, map_location='cpu')['twenty_step_model']
     pretrained_dict = {key.replace("module.", ""): value for key, value in pretrained_dict.items()}
 
@@ -94,11 +92,10 @@ def main(_):
           tgt_seq_len = 1
           generated_frames_num = music_length - tgt_seq_len
 
-          hidden, dec_output, out_seq = model.init_decoder_hidden(b)
+          hidden, dec_output, out_seq = model.initialise_decoder(b)
           a, c = hidden
 
-          enc_mask = get_subsequent_mask(music_tensor, 142)
-          enc_outputs, *_ = model.encoder(music_tensor, pos, enc_mask)
+          enc_outputs, *_ = model.encoder(music_tensor, pos)
 
           preds = []
           for i in range(tgt_seq_len):
diff --git a/train.py b/train.py
index 21b5218..f7fbe7b 100644
--- a/train.py
+++ b/train.py
@@ -51,7 +51,7 @@ random.seed(seed)
 WANDB_API_KEY ="f29aca38281e9a7657e6661c5684aa35fecf37ce"
 
 
-def train(maxEpochs, train_loader,  optimizer, criterion, device, encoder, decoder, model, data_dir):
+def train(maxEpochs, train_loader,  optimizer, criterion, scheduler, device, encoder, decoder, model, data_dir):
 
     steps = 0
     for epoch in range(1, maxEpochs+1):
@@ -94,7 +94,8 @@ def train(maxEpochs, train_loader,  optimizer, criterion, device, encoder, decod
             # Track loss
             current_loss = current_loss + loss.item()
 
-        if epoch == 1000:
+        if epoch == 1:
+            print("step")
             scheduler.step()
 
         if epoch == 2000:
@@ -104,7 +105,7 @@ def train(maxEpochs, train_loader,  optimizer, criterion, device, encoder, decod
         train_log(current_loss, steps, epoch)
 
         if(epoch%500 == 0) :
-            torch.save(model.state_dict(), "model.h5")
+            torch.save(model.state_dict(), wandb.run.name +".h5")
             wandb.save('model.h5')
 
         if ((epoch+1)%10 == 0):
@@ -175,7 +176,7 @@ def main(_):
 
     model = nn.DataParallel(model).to(device) if torch.cuda.is_available() else model.to(device)
 
-    train(config.maxEpochs, train_loader, optimizer, criterion,  device, encoder, decoder, model, config.data_dir)
+    train(config.maxEpochs, train_loader, optimizer, criterion, scheduler,  device, encoder, decoder, model, config.data_dir)
 
 
 if __name__ == '__main__':
diff --git a/wandb/latest-run b/wandb/latest-run
index aa30e10..98bbd12 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20210928_001712-1y07wtlj
\ No newline at end of file
+run-20210928_135850-26w8lqs1
\ No newline at end of file
